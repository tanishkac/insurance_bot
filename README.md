
---

# Insurance Policy Q\&A Assistant (RAG)

This project implements a **Retrieval-Augmented Generation (RAG) system** that allows users to upload **insurance policy PDFs** and ask natural language questions about them. The system processes the documents, stores vector embeddings, and retrieves relevant content to generate accurate answers.

---

## Features

* Upload **PDF documents** (insurance policies).
* Automatic **text extraction, chunking, and embedding**.
* Vector storage in **ChromaDB**.
* Natural language Q\&A powered by **LangChain + LLMs**.
* **Frontend (React)**: clean interface for upload & queries.
* **Backend (FastAPI, Python)**: handles preprocessing and retrieval.

---

## System Architecture

**Flow:**

1. User uploads an insurance policy PDF (frontend).
2. Backend extracts text, chunks it, generates embeddings, and stores them in **ChromaDB**.
3. User submits a question.
4. Backend retrieves relevant chunks and uses a language model via **LangChain** to generate an answer.
5. Frontend displays the answer.

---

## ğŸ“‚ Project Structure

```
project-root/
â”œâ”€â”€ backend/                 # FastAPI backend
â”‚   â”œâ”€â”€ api/                 # API routes
â”‚   â”‚   â””â”€â”€ main.py
â”‚   â”‚
â”‚   â”œâ”€â”€ app/                 # Core application logic
â”‚   â”‚   â”œâ”€â”€ chunker/         # Splits extracted text into chunks
â”‚   â”‚   â”‚   â””â”€â”€ chunk.py
â”‚   â”‚   â”œâ”€â”€ config/          # Configurations and settings
â”‚   â”‚   â”‚   â””â”€â”€ settings.py
â”‚   â”‚   â”œâ”€â”€ embedding/       # Embedding generation
â”‚   â”‚   â”‚   â””â”€â”€ embed.py
â”‚   â”‚   â”œâ”€â”€ llm/             # LLM utilities (retrieval-augmented generation)
â”‚   â”‚   â”œâ”€â”€ pdf_loader/      # PDF text extraction
â”‚   â”‚   â”œâ”€â”€ retriever/       # Retrieval logic
â”‚   â”‚   â””â”€â”€ utils/           # Helper utilities
â”‚   â”‚
â”‚   â”œâ”€â”€ data/                # Uploaded PDFs or processed text
â”‚   â”œâ”€â”€ vectorstores/        # ChromaDB vector storage
â”‚   â””â”€â”€ myenv/               # Local Python environment (ignored in Git)
â”‚
â”œâ”€â”€ frontend/                # React frontend
â”‚   â”œâ”€â”€ src/                 # Components, pages, services
â”‚   â””â”€â”€ package.json
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

---

## âš™ï¸ Tech Stack

* **Frontend:** React
* **Backend:** FastAPI, Python
* **Vector DB:** ChromaDB
* **Orchestration:** LangChain
* **PDF Processing:** PyPDFLoader
* **Model Provider:** Ollama

---

## â–¶ï¸ Getting Started

### 1. Clone the Repository

```bash
git clone https://github.com/tanishkac/insurance_bot
cd your-repo
```

### 2. Setup Backend

```bash
cd backend
pip install -r requirements.txt
uvicorn api.main:app --reload
```

### 3. Setup Frontend

```bash
cd frontend
npm install
npm start
```

### 4. Usage

1. Upload an insurance policy PDF from the frontend.
2. Ask natural language questions.
3. Receive context-aware answers.

---

## Future Enhancements

* Multi-PDF support.
* Chat history (conversational context).
* More file format support (Word, Excel).
* Deployment on **Vercel (frontend)** + **Render/Heroku (backend)**.

---

## Conclusion

This project demonstrates how **RAG (Retrieval Augmented Generation)** can make complex insurance policies accessible to users by enabling natural language queries. It integrates **React + FastAPI + LangChain + ChromaDB** to create an end-to-end intelligent assistant.


